!pip install opencv-python-headless
#!/opt/ohpc/pub/apps/python/3.9.10/bin/python3.9 -m pip install --upgrade pip

import cv2

!pip install git+https://github.com/bowang-lab/MedSAM.git

 #Download and save SAM Checkpoint
#!mkdir -p work_dir/SAM
#!wget -O work_dir/SAM/sam_vit_b_01ec64.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
#!mkdir -p work_dir/MedSAM    
!wget -O /home/u18/shri198/work_dir/MedSAM/medsam_vit_b.pth https://zenodo.org/records/10689643/files/medsam_vit_b.pth

!pip install --upgrade nibabel

!python3 -m venv --help

!python3 -m venv /home/u18/shri198/medsam

!source /home/u18/shri198/medsam/bin/activate

!git clone https://github.com/bowang-lab/MedSAM

%cd MedSAM

!pip install -e .

import cv2
import os

#Define the path to the image
image_path = '/home/u18/shri198/data/images/0.png'

# Load the image using OpenCV
image = cv2.imread(image_path)

if image is not None:
    # Print the shape of the image
    print("Image shape:", image.shape)
else:
    print("Error: Image not found or unable to load.")

import cv2
import numpy as np
import os

def preprocess_retinal_image(image_path):
    """
    Preprocesses a retinal image and its corresponding mask for vessel segmentation.

    Parameters:
    image_path (str): Path to the input retinal image.

    Returns:
    preprocessed_image (numpy.ndarray): The preprocessed retinal images
    """
    image = cv2.imread(os.path.join(image_path,i))
    #mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    # Step 2: Separate channels (BGR)
    b, g, r = cv2.split(image)

    # Step 3: Histogram Equalization for each channel
    b_eq = cv2.equalizeHist(b)
    g_eq = cv2.equalizeHist(g)
    r_eq = cv2.equalizeHist(r)

    # Step 4: Merge channels back together
    equalized_image = cv2.merge([b_eq, g_eq, r_eq])
    # Step 2: Convert the image to grayscale
    #gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

      # Step 3: Resize the image to (256, 256)
    #resized_image = cv2.resize(gray_image, (256, 256))

    # Step 3: Histogram Equalization
    #equalized_image = cv2.equalizeHist(image)

    # Step 4: Denoising using Gaussian filter
    denoised_image = cv2.GaussianBlur(equalized_image, (5, 5), 0)

    # Step 5: Morphological operations
    # Use a kernel for morphological operations
    kernel = np.ones((3, 3), np.uint8)

    # Top-hat transformation
    tophat = cv2.morphologyEx(denoised_image, cv2.MORPH_TOPHAT, kernel)

    # Step 6: Normalization
    normalized_image = cv2.normalize(tophat, None, 0, 255, cv2.NORM_MINMAX)

     # Step 8: Expand dimensions to match the expected input shape (256, 256, 1)
    #preprocessed_image = np.expand_dims(normalized_image, axis=-1)

    return normalized_image



import cv2
import numpy as np
import os

def preprocess_retinal_mask(mask_path):
    """
    Preprocesses a retinal image and its corresponding mask for vessel segmentation.

    Parameters:
    image_path (str): Path to the input retinal image.

    Returns:
    preprocessed_image (numpy.ndarray): The preprocessed retinal images
    """
    #image = cv2.imread(os.path.join(images_path,i))
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    print(mask.shape)
     # Step 2: Resize the mask to (256, 256)
    #resized_mask = cv2.resize(mask, (256, 256))

    # Step 2:Binarize the mask
    _, binary_mask  = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)


# Step 4: Expand dimensions to match the expected input shape (256, 256, 1)
    #preprocessed_mask = np.expand_dims(binary_mask, axis=-1)

    return binary_mask



images_path = '/home/u18/shri198/data/images'
masks_path = '/home/u18/shri198/data/labels'

for i in os.listdir(images_path):
  img_num = i.split(".")[0]
  image_path = os.path.join(images_path,i)
  print(image_path)
  preprocessed_image = preprocess_retinal_image(images_path)
  file = "/home/u18/shri198/data/processed_images/{img_num}.npy".format(img_num=img_num)
  np.save(file,preprocessed_image)
  print(preprocessed_image)
  # If you want to visualize the results using OpenCV
  '''
  cv2.imshow("Preprocessed Image", preprocessed_image)
  #cv2.imshow("Preprocessed Mask", preprocessed_mask)
  cv2.waitKey(0)
  cv2.destroyAllWindows()
  '''

masks_path = '/home/u18/shri198/data/labels'
for i in os.listdir(masks_path):
  mask_num = i.split(".")[0]
  mask_path = os.path.join(masks_path,i)
  print(mask_path)
  binary_mask1 = preprocess_retinal_mask(mask_path)
  file = "/home/u18/shri198/data/processed_labels/{mask_num}.npy".format(mask_num=mask_num)
  np.save(file,binary_mask1)
  print(binary_mask1)
  # If you want to visualize the results using OpenCV


print(binary_mask1.shape)


print(preprocessed_image.shape)

import matplotlib.pyplot as plt

!pip install numpy==1.21.2


!python3 train_one_gpu.py

!pip install torchvision
import torchvision

--Inference


# %% load environment
import numpy as np
import matplotlib.pyplot as plt
import os

join = os.path.join
import torch
from segment_anything import sam_model_registry
from skimage import io, transform
import torch.nn.functional as F
import argparse


# visualization functions
# source: https://github.com/facebookresearch/segment-anything/blob/main/notebooks/predictor_example.ipynb
# change color to avoid red and green
def show_mask(mask, ax, random_color=False):
    print("called")
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        color = np.array([251 / 255, 252 / 255, 30 / 255, 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)


def show_box(box, ax):
    x0, y0 = box[0], box[1]
    w, h = box[2] - box[0], box[3] - box[1]
    ax.add_patch(
        plt.Rectangle((x0, y0), w, h, edgecolor="blue", facecolor=(0, 0, 0, 0), lw=2)
    )

@torch.no_grad()
def medsam_inference(medsam_model, img_embed, box_1024, H, W):
    box_torch = torch.as_tensor(box_1024, dtype=torch.float, device=img_embed.device)
    if len(box_torch.shape) == 2:
        box_torch = box_torch[:, None, :]  # (B, 1, 4)

    sparse_embeddings, dense_embeddings = medsam_model.prompt_encoder(
        points=None,
        boxes=box_torch,
        masks=None,
    )
    low_res_logits, _ = medsam_model.mask_decoder(
        image_embeddings=img_embed,  # (B, 256, 64, 64)
        image_pe=medsam_model.prompt_encoder.get_dense_pe(),  # (1, 256, 64, 64)
        sparse_prompt_embeddings=sparse_embeddings,  # (B, 2, 256)
        dense_prompt_embeddings=dense_embeddings,  # (B, 256, 64, 64)
        multimask_output=False,
    )

    low_res_pred = torch.sigmoid(low_res_logits)  # (1, 1, 256, 256)

    low_res_pred = F.interpolate(
        low_res_pred,
        size=(H, W),
        mode="bilinear",
        align_corners=False,
    )  # (1, 1, gt.shape)
    low_res_pred = low_res_pred.squeeze().cpu().numpy()  # (256, 256)
    medsam_seg = (low_res_pred > 0.5).astype(np.uint8)
    return medsam_seg
    
#%% load model and image
MedSAM_CKPT_PATH = "/home/u18/shri198/work_dir/MedSAM/medsam_vit_b.pth"
device = "cuda:0"
medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)
medsam_model = medsam_model.to(device)
medsam_model.eval()

basepath = "/home/u18/shri198/data/images"
num_images=1
image_files = [f for f in os.listdir(basepath)]
for i, image_file in enumerate(image_files[:num_images]):
    image_path = os.path.join(basepath, image_file)
    print(image_path)
    img_np = io.imread(image_path)
    #nt=nt+1
#img_np = io.imread('/home/u6/mbaid/MedSAM/assets/71.png')
    plt.imshow(img_np)
    plt.show()
    if len(img_np.shape) == 2:
        img_3c = np.repeat(img_np[:, :, None], 3, axis=-1)
    else:
        img_3c = img_np
    H, W, _ = img_3c.shape
    
    # %% image preprocessing
    img_1024 = transform.resize(img_3c, (1024, 1024), order=3, preserve_range=True, anti_aliasing=True).astype(np.uint8)
    img_1024 = (img_1024 - img_1024.min()) / np.clip(img_1024.max() - img_1024.min(), a_min=1e-8, a_max=None)  # normalize to [0, 1], (H, W, 3)
    # convert the shape to (3, H, W)
    img_1024_tensor = (torch.tensor(img_1024).float().permute(2, 0, 1).unsqueeze(0).to(device))
    # Prompt the user for box dimensions
    box = input(f"Enter the bounding box for image {i+1} (format: [x1, y1, x2, y2]): ")

    # Convert the input box string to a NumPy array
    try:
        box_np = np.array([[int(x) for x in box[1:-1].split(',')]])
    except ValueError:
        print("Invalid box format. Please enter the bounding box in the format [x1, y1, x2, y2].")
        continue
    #box_np = np.array([[350,100, 460, 210]])
    print(box_np)
    # transfer box_np t0 1024x1024 scale
    box_1024 = box_np / np.array([W, H, W, H]) * 1024
    with torch.no_grad():
        image_embedding = medsam_model.image_encoder(img_1024_tensor)  # (1, 256, 64, 64)
    medsam_seg = medsam_inference(medsam_model, image_embedding, box_1024, H, W)
        
    # %% visualize results
    fig, ax = plt.subplots(1, 2, figsize=(10, 5))
    ax[0].imshow(img_3c)
    show_box(box_np[0], ax[0])
    ax[0].set_title("Input Image and Bounding Box")
    ax[1].imshow(img_3c)
    show_mask(medsam_seg, ax[1])
    show_box(box_np[0], ax[1])
    ax[1].set_title("MedSAM Segmentation")
    plt.show()
    
    
--Performance

import numpy as np
from scipy.spatial.distance import directed_hausdorff
from skimage.metrics import structural_similarity as ssim

def dice_coefficient(y_true, y_pred):
    intersection = np.sum(y_true * y_pred)
    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred))

def iou_score(y_true, y_pred):
    intersection = np.logical_and(y_true, y_pred)
    union = np.logical_or(y_true, y_pred)
    return np.sum(intersection) / np.sum(union)

def hausdorff_distance(y_true, y_pred):
    return max(directed_hausdorff(y_true, y_pred)[0], directed_hausdorff(y_pred, y_true)[0])

def compare_masks(ground_truth, prediction):
    # Ensure masks are binary
    gt = ground_truth.astype(bool)
    pred = prediction.astype(bool)
    
    # Calculate metrics
    dice = dice_coefficient(gt, pred)
    iou = iou_score(gt, pred)
    hausdorff = hausdorff_distance(gt, pred)
    
    # Convert to float for SSIM calculation
    gt_float = gt.astype(float)
    pred_float = pred.astype(float)
    
    # Calculate SSIM with specified data_range
    ssim_score = ssim(gt_float, pred_float, data_range=1.0)
    
    return {
        "Dice Coefficient": dice,
        "IoU Score": iou,
        "Hausdorff Distance": hausdorff,
        "SSIM": ssim_score
    }

# Example usage
ground_truth = np.load('/home/u18/shri198/data/processed_labels/0.npy')
medsam_prediction = np.load('/home/u18/shri198/data/predicted_labels/0_pred.npy')
results = compare_masks(ground_truth, medsam_prediction)
for metric, value in results.items():
    print(f"{metric}: {value}")
